{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMgAXso+jhznryrpNZ2RxU0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tarunjeev/App/blob/main/NLP.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pzj7H007lvBC"
      },
      "source": [
        "                                                                                      # The followwing are part of NLU - Natural Language Understanding\n",
        "# Nlp  - Natural language Processsing\n",
        "# Nlg -  Naturla language Generation - You generate languages, for e.g. machine should be able to make couple of tweets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jdj4IJxBhpcs"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibpeMGVnnQQF"
      },
      "source": [
        "Tokenization - Breaking a sentence into multiple pieces is the process of tokenization. After that we convert tokens into matrix called TDM\n",
        "TDM - Term Document Matrix.\n",
        "Bag of Words - A set of words that are collected from the tokenization process so that you can construct your own set of words that can be used to create your own semantics\n",
        "Once you have the TDM then you can train an algorithm to model and prdict accordingly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VzPSJb2oRXx"
      },
      "source": [
        "Tokens : Include everything\n",
        "BOW : Includes relevant tokens\n",
        "**Ngram Extraction**\n",
        "Ngram : 1 word - 1 gram, 2 words - bigram, 3 words - trigram, 4 words - fourgram, 5 words - 5gram\n",
        "For e.g. Customer is 1 gram, Customer Relationship is bigram\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSM3hJjnmP4m"
      },
      "source": [
        "text = 'AI gradually restored its reputation in the late 1990s and early 21st century by finding specific solutions to specific problems. The narrow focus allowed researchers to produce verifiable results, exploit more mathematical methods, and collaborate with other fields (such as statistics, economics and mathematics).'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "3Z1TenYqp5Jc",
        "outputId": "37aa4d14-2d9b-4625-838f-3ea954d6c7df"
      },
      "source": [
        "text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'AI gradually restored its reputation in the late 1990s and early 21st century by finding specific solutions to specific problems. The narrow focus allowed researchers to produce verifiable results, exploit more mathematical methods, and collaborate with other fields (such as statistics, economics and mathematics).'"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvHHo_vuqHBc"
      },
      "source": [
        "#tokenization\n",
        "tokens = text.split()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HsviRUFnqUwX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b473d75c-2ac4-4b18-ae90-6ffb150663a4"
      },
      "source": [
        "tokens"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AI',\n",
              " 'gradually',\n",
              " 'restored',\n",
              " 'its',\n",
              " 'reputation',\n",
              " 'in',\n",
              " 'the',\n",
              " 'late',\n",
              " '1990s',\n",
              " 'and',\n",
              " 'early',\n",
              " '21st',\n",
              " 'century',\n",
              " 'by',\n",
              " 'finding',\n",
              " 'specific',\n",
              " 'solutions',\n",
              " 'to',\n",
              " 'specific',\n",
              " 'problems.',\n",
              " 'The',\n",
              " 'narrow',\n",
              " 'focus',\n",
              " 'allowed',\n",
              " 'researchers',\n",
              " 'to',\n",
              " 'produce',\n",
              " 'verifiable',\n",
              " 'results,',\n",
              " 'exploit',\n",
              " 'more',\n",
              " 'mathematical',\n",
              " 'methods,',\n",
              " 'and',\n",
              " 'collaborate',\n",
              " 'with',\n",
              " 'other',\n",
              " 'fields',\n",
              " '(such',\n",
              " 'as',\n",
              " 'statistics,',\n",
              " 'economics',\n",
              " 'and',\n",
              " 'mathematics).']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2Qn-d4Gqb51"
      },
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zx3PAYJ-GZh7",
        "outputId": "197e76c1-08bc-4426-8a7b-3a8377f0ca97"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WpH7kNaAGnGM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "566309c7-0b64-477a-af80-237df33f3ff7"
      },
      "source": [
        "word_tokenize(text)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['AI',\n",
              " 'gradually',\n",
              " 'restored',\n",
              " 'its',\n",
              " 'reputation',\n",
              " 'in',\n",
              " 'the',\n",
              " 'late',\n",
              " '1990s',\n",
              " 'and',\n",
              " 'early',\n",
              " '21st',\n",
              " 'century',\n",
              " 'by',\n",
              " 'finding',\n",
              " 'specific',\n",
              " 'solutions',\n",
              " 'to',\n",
              " 'specific',\n",
              " 'problems',\n",
              " '.',\n",
              " 'The',\n",
              " 'narrow',\n",
              " 'focus',\n",
              " 'allowed',\n",
              " 'researchers',\n",
              " 'to',\n",
              " 'produce',\n",
              " 'verifiable',\n",
              " 'results',\n",
              " ',',\n",
              " 'exploit',\n",
              " 'more',\n",
              " 'mathematical',\n",
              " 'methods',\n",
              " ',',\n",
              " 'and',\n",
              " 'collaborate',\n",
              " 'with',\n",
              " 'other',\n",
              " 'fields',\n",
              " '(',\n",
              " 'such',\n",
              " 'as',\n",
              " 'statistics',\n",
              " ',',\n",
              " 'economics',\n",
              " 'and',\n",
              " 'mathematics',\n",
              " ')',\n",
              " '.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xpfyrTnHQ2V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa9f59bb-3d49-4f29-c860-5d11f532e36c"
      },
      "source": [
        "tweet1 = '#NLPProc can be made better using @deeplearning'\n",
        "word_tokenize(tweet1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['#', 'NLPProc', 'can', 'be', 'made', 'better', 'using', '@', 'deeplearning']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AazWbJFGHq65"
      },
      "source": [
        "from nltk.tokenize import TweetTokenizer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ReBKsr_2H7-5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6b55c63-5705-441c-e392-05a4eb14c9a4"
      },
      "source": [
        "tokenizer = TweetTokenizer()\n",
        "tokenizer.tokenize(tweet1)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['#NLPProc', 'can', 'be', 'made', 'better', 'using', '@deeplearning']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UdVKl-OzIbYv"
      },
      "source": [
        "Steming  - it is the process of getting back to the root word"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "ceFGdHBcKaD5",
        "outputId": "fcf54905-8c39-447e-fcc0-2a6a55d09b9d"
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "s = PorterStemmer()\n",
        "s\n",
        "s.stem('Learning')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'learn'"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "Ttmhy-WGIXzF",
        "outputId": "eefcba8e-71a5-495b-f379-a6f6a6bf2c96"
      },
      "source": [
        "s.stem('Learnt')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'learnt'"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "yFseYnMEK1VH",
        "outputId": "967c5068-1f9a-48c7-f435-6c45103093b9"
      },
      "source": [
        "s.stem('Learned')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'learn'"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sM84gDhlK5pp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "outputId": "b7547d06-7bb6-4e1e-a9ec-7b9920c2b50c"
      },
      "source": [
        "s.stem('Learn')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'learn'"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emQne9tKLIq8"
      },
      "source": [
        "Lemmatization - for example run, running, ran are all forms of the word run, therefore run is the lemma of all the words. \n",
        "Lemma - a proper word\n",
        "Input words are lemmatised according to the POS tags (Part of speech)\n",
        "For e.g. verb, noun, adj, adv, np, vp"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaG_A2iyL-zQ"
      },
      "source": [
        "from nltk.stem import WordNetLemmatizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhPH58kpMEgg",
        "outputId": "fee8af0d-45e2-4f81-a0b9-9fcd5a674bb6"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "To-oxKwTMHGY",
        "outputId": "d79f8b14-e50f-43a0-d740-5352e0995e57"
      },
      "source": [
        "s.lemmatize('fishing', pos='v')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-b254ee0929e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fishing'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'v'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'PorterStemmer' object has no attribute 'lemmatize'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OIMRwgyJMdyv"
      },
      "source": [
        "s.lemmatize('fish', pos='v')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYePPNA8M-9d"
      },
      "source": [
        "s.lemmatize('fisher',pos='n')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZQ4kEdfNF3j"
      },
      "source": [
        "s.lemmatize('fished', pos='v')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-c_6xXrNMJc"
      },
      "source": [
        "#Major Tasks\n",
        "# Sentiment Analysis\n",
        "# Text Classification\n",
        "# Topic Modelling\n",
        "# Text Summarisation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fct95DcANeN1"
      },
      "source": [
        " Reuters - 21578 Collection\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YPE1q25vOWlo"
      },
      "source": [
        "from nltk.corpus import reuters \n",
        "\n",
        "# corpus is a collection of documents"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mpeK2ROO4CQ"
      },
      "source": [
        "import nltk\n",
        "nltk.download('reuters')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhWNE0bQOe4v"
      },
      "source": [
        "#list of document ids from the dataset, these documents are already built inside the library\n",
        "# textual information using natural language processing\n",
        "# programming - strucutured\n",
        "#natural language - framework\n",
        "# ambiguous\n",
        "# changing and volving over time\n",
        "#expressing, perceiving & interpreting\n",
        "# formally understanding the rules of language\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69EjjiIxWJL2"
      },
      "source": [
        "- process and analyze\n",
        "- unstructured data such as twitter, insta, facebook\n",
        "- ML algorithms take data in numeric format\n",
        "- numeric representation of the textual data\n",
        "- human to computer interaction\n",
        "- read text\n",
        "- interpret it\n",
        "- measure the statement\n",
        "- determine which parts are important\n",
        "- computer should be able to get some information out of it\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXYQwIGgXHRD"
      },
      "source": [
        "nltk - Natural Language toolkit\n",
        "nltk gives us all the tools to create the python program\n",
        "human data is unstrucutred form of data\n",
        "nltk helps computer to understand human data and helps it to clean and analyze the unstructured human data\n",
        "things that can be done using nltk are classification, stemming, tokenization, tagging\n",
        "nltk is free and open source and is community driven project\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCexzz0bzsuz"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7X44fdmFYrQy",
        "outputId": "144b4c0b-fb43-45ce-e476-a958417787d8"
      },
      "source": [
        "!nltk.download_gui()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: -c: line 1: syntax error: unexpected end of file\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vQhhmHibXkZB"
      },
      "source": [
        "import re #for regular expression\n",
        "import os #operating system\n",
        "import csv # csv files download\n",
        "#import nltk.stem.snowball import SnowballStemmer\n",
        "import random\n",
        "from nltk.classify import SklearnClassifier\n",
        "from nltk.tokenize import  RegexpTokenizer\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "import numpy as np\n",
        "import pandas as pd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VCaymMxEaTFz"
      },
      "source": [
        "# Get multiple outputsin the same shell\n",
        "from IPython.core.interactiveshell import InteractiveShell\n",
        "InteractiveShell.ast_node_interactivity = \"all\"\n",
        "\n",
        "#Ignore all the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "warnings.filterwarnings(action='ignore', category = DeprecationWarning)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QkhvloqObGXz"
      },
      "source": [
        "#Display all rows and olumns of a dataframe instead of a truncated version\n",
        "from IPython.display import display\n",
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7lVJBtVsbjXZ"
      },
      "source": [
        "**Preprocess**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "49xUHAm5bi5K"
      },
      "source": [
        "sentence = \"The Big brown box jumped over a lazy dog\"\n",
        "sentence2 = \"Thisis particularly important in today's world where we are swamped with unstructured natural language daa on the variety of social media platforms poeple engage in now-a-days (note = now-a-days in the decade of 2010-2020)\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s85V53qMcc6W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "ee8bf158-c0bb-4a7b-87d6-a0e9cf0640c8"
      },
      "source": [
        "#convert sentence to lower case\n",
        "'This' == 'this'\n",
        "print('AbcdEFgH'.lower())\n",
        "sentence.lower()\n",
        "sentence2.lower()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "abcdefgh\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'the big brown box jumped over a lazy dog'"
            ]
          },
          "metadata": {},
          "execution_count": 25
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"thisis particularly important in today's world where we are swamped with unstructured natural language daa on the variety of social media platforms poeple engage in now-a-days (note = now-a-days in the decade of 2010-2020)\""
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fFAWwWtcwtK"
      },
      "source": [
        "**Tokenize - extract individual words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rNQWW3hcc-72",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e266d08-1325-42a7-f1c0-9ec667dd7f91"
      },
      "source": [
        "#Tokenization is the process of breaking down texts into smaller chunks called tokens\n",
        "# Alos called engrams.\n",
        "# Creates a vocabulory\n",
        "tokenizer = RegexpTokenizer(r'\\w+')\n",
        "tokens = tokenizer.tokenize(sentence)\n",
        "tokens\n",
        "tokens2 = tokenizer.tokenize(sentence2)\n",
        "tokens2"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'Big', 'brown', 'box', 'jumped', 'over', 'a', 'lazy', 'dog']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Thisis',\n",
              " 'particularly',\n",
              " 'important',\n",
              " 'in',\n",
              " 'today',\n",
              " 's',\n",
              " 'world',\n",
              " 'where',\n",
              " 'we',\n",
              " 'are',\n",
              " 'swamped',\n",
              " 'with',\n",
              " 'unstructured',\n",
              " 'natural',\n",
              " 'language',\n",
              " 'daa',\n",
              " 'on',\n",
              " 'the',\n",
              " 'variety',\n",
              " 'of',\n",
              " 'social',\n",
              " 'media',\n",
              " 'platforms',\n",
              " 'poeple',\n",
              " 'engage',\n",
              " 'in',\n",
              " 'now',\n",
              " 'a',\n",
              " 'days',\n",
              " 'note',\n",
              " 'now',\n",
              " 'a',\n",
              " 'days',\n",
              " 'in',\n",
              " 'the',\n",
              " 'decade',\n",
              " 'of',\n",
              " '2010',\n",
              " '2020']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xblHLqUegHD4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "722361b3-84fc-48ba-e5c7-b9388faca659"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NddQsSjxfMf9"
      },
      "source": [
        "**Stopwords: Filter words to remove non-useful words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ltG7dfrfLdI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "abf7c468-d169-4be2-ca83-c11d7eef635b"
      },
      "source": [
        "# technique used to filter non useful words\n",
        "# stopwords are te ones which does not add much meaning to a sentence\n",
        "# they can easily be ignored rather than acrificing the meaning of the sentence\n",
        "# e.g the is that\n",
        "filtered_words = [w for w in tokens if not w in stopwords.words('english')]\n",
        "filtered_words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The', 'Big', 'brown', 'box', 'jumped', 'lazy', 'dog']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVdRcIqpgRoK"
      },
      "source": [
        "filtered_words1 = [w for w in tokens2 if not w in stopwords.words('english')]\n",
        "filtered_words1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRBJ6CjVgdrK"
      },
      "source": [
        "def preprocess(sentence):\n",
        "  sentence.lower()\n",
        "  tokenizer = RegexpTokenizer(r'\\w+')\n",
        "  tokens = tokenizer.tokenize(sentence)\n",
        "  filtered_words = [w for w in tokens if not w in stopwords.words('english')]\n",
        "  return filtered_words"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnQxN3lyg82s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09b18431-116c-40dd-b2b9-a8f6e4d04582"
      },
      "source": [
        "preprocessed_sentence = preprocess(sentence)\n",
        "print(preprocessed_sentence)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'Big', 'brown', 'box', 'jumped', 'lazy', 'dog']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4-xzFEU8hLXy"
      },
      "source": [
        "preprocess(sentence2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8KTVheqiouk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c3f4dc0-50d9-4780-b609-82656ee5c00d"
      },
      "source": [
        "import nltk\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xudDE3rmhPJo"
      },
      "source": [
        "**Tagging**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bn1KowmXhtxv"
      },
      "source": [
        "# process of classifying words into their parts of speech and labelling them accordingly\n",
        "# so nltk has a function pos_tag where we can give a preprocess sentence and it tags the textual information for us\n",
        "tags = nltk.pos_tag(preprocessed_sentence)\n",
        "print(tags)\n",
        "# so it has been specified that  if its a noun, verb, vowels , past tense and so on\n",
        "tags = nltk.pos_tag(preprocess(sentence2))\n",
        "tags"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OlhYQ4pxiL34"
      },
      "source": [
        "def extract_tagged(sentences):\n",
        "  features = []\n",
        "  for tagged_word in sentences:\n",
        "    word,tag = tagged_word\n",
        "    if tag == 'NN' or tag =='VBN' or tag == 'NNS' or tag == 'VBP' or tag == 'RB' or tag == 'VBZ' or tag == 'VBG':\n",
        "      features.append(word)\n",
        "  return features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn9CCqYWkW8Z"
      },
      "source": [
        "extract_tagged(tags)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNeu1cXfjcxc",
        "outputId": "a83f62d8-e9c9-4e7d-b352-0cf124c71bb9"
      },
      "source": [
        "import nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiDtbrLXhryC"
      },
      "source": [
        "**Lemmatize Words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQEbTT6Xhq62"
      },
      "source": [
        "# Lemmatization is the process of grouping together the different inflected forms of words\n",
        "# and analyz it as a single item. Brings more context to te words.So it links words with similar\n",
        "# meanings to one word. It is also a way of doing things properly with the use of vocabulory\n",
        "#and morphological analysis of the words. returns the base of the dictionary calle lemma\n",
        "lmtar = WordNetLemmatizer()\n",
        "print(lmtar.lemmatize('cacti'))\n",
        "print(lmtar.lemmatize('willing'))\n",
        "print(lmtar.lemmatize('feet'))\n",
        "print(lmtar.lemmatize('stemmed'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3iPEKtfjsIF"
      },
      "source": [
        "**Stem Words**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OK0ycbBLjoGL",
        "outputId": "51df291d-30fd-48a4-f1b1-9e3f97f41307"
      },
      "source": [
        "# Stemming is kind of a normalization for the words and normalization is a technique where a\n",
        "# set of words in a sentence are converted into a sequence that is shorten its lookup\n",
        "# The words which have same meaning but have some variation according to the context or\n",
        "# sentence are normalized. In other words there is a root word but there are many variation \n",
        "# for that root word e.g., stem, stemmed, stemming\n",
        "from nltk.stem.snowball import SnowballStemmer \n",
        "words_for_stemming = ['stem', 'stemming', 'stemmed', 'stemmer','stems','feet','willing']\n",
        "stemmer = SnowballStemmer('english')\n",
        "[stemmer.stem(x) for x in words_for_stemming]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['stem', 'stem', 'stem', 'stemmer', 'stem', 'feet', 'will']"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wM1WsgYVly0P"
      },
      "source": [
        "**Putting it all together**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkjDMHn-l3ky"
      },
      "source": [
        "def extract_feature(text):\n",
        "  words = preprocess(text)\n",
        "  # print('words : ', words)\n",
        "  tags = nltk.pos_tag(words)\n",
        "  # print('tags: ', tags)\n",
        "  extracted_features = extract_tagged(tags)\n",
        "  # print(' Extracted featueres: ', extracted_features )\n",
        "  stemmed_words = [stemmer.stem(x) for x in extracted_features]\n",
        "  # print(stemmed_words)\n",
        "  result = [lmtar.lemmatize(x) for x in stemmed_words]\n",
        "  return result\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sw9jBDBsoTH-"
      },
      "source": [
        "#2sentence\n",
        "words = extract_feature(sentence2)\n",
        "print(words)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfMdwJIxot_I",
        "outputId": "7e36e0c9-2052-4aa9-a17f-67d899e970f7"
      },
      "source": [
        "extract_feature(\"He hurt his right foot while he was wearing white shoes on his feet\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['foot', 'wear', 'shoe', 'foot']"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yTaVSvP4pD_5"
      },
      "source": [
        "**Implementing Bag of words**\n",
        "In simple terms, it's a collection of words to represent a sentence, disregarding the order in which they appear"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwtGmqPBpUEg"
      },
      "source": [
        "def word_feats(words):\n",
        "  return dict([(word, True) for word in words])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zEiwkNy9qAbc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf1033d9-fd22-4469-8769-b8f49147ae12"
      },
      "source": [
        "word_feats(words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'daa': True,\n",
              " 'day': True,\n",
              " 'decad': True,\n",
              " 'languag': True,\n",
              " 'medium': True,\n",
              " 'note': True,\n",
              " 'particular': True,\n",
              " 'platform': True,\n",
              " 'today': True,\n",
              " 'varieti': True,\n",
              " 'world': True}"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "46BkP_9zqIHI"
      },
      "source": [
        "**NLP CHATBOT ENGINE**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giVuSGEasn2B"
      },
      "source": [
        "*Supervised Machine Learning*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2WRsQLMUqSUu"
      },
      "source": [
        "*Parsing the whole document*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUia6NcRqdn4"
      },
      "source": [
        "Create a chatbot which is a leave inquiry system\n",
        "So there will be a user which will give reply\n",
        "Now the replies given could be texts which can be categorized\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "elB9IzDor8v-"
      },
      "source": [
        "def extract_feature_from_doc(data):\n",
        "  result = []\n",
        "  corpus = []\n",
        "  #The responses of the chat bot\n",
        "  answers = {}\n",
        "  for (text, category, answer) in data:\n",
        "    features = extract_feature(text)\n",
        "    corpus.append(features)\n",
        "    result.append((word_feats(features), category))\n",
        "    answers[category] = answer\n",
        "  return (result, sum(corpus,[]), answers)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dqvyz6M_6O-j"
      },
      "source": [
        "extract_feature_from_doc([['this is the input text from the user','category','answer to give']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmTQXOtQ-eKn"
      },
      "source": [
        "def get_content(filename):\n",
        "  doc = os.path.join(filename)\n",
        "  with open(doc,'r') as content_file:\n",
        "    lines = csv.reader(content_file,delimiter='|')\n",
        "    data = [x for x in lines if len(x) == 3]\n",
        "    return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wb05s6TgOzxC",
        "outputId": "cceed737-d53b-48b6-acee-5d188962025d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "9b6AsiwgP3Mv",
        "outputId": "9e348cb4-1cd8-4a46-8e33-3f55455a12df"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9dad9e74-ca35-432d-be88-e2c591b6ee2a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9dad9e74-ca35-432d-be88-e2c591b6ee2a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving leaves.txt to leaves.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34QoLPDdAFuc",
        "outputId": "8b1ce662-3159-4e82-e9af-28f1907885ee"
      },
      "source": [
        "filename = 'leaves.txt'\n",
        "data = get_content(filename)\n",
        "data\n",
        "#print(filename.read(2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Hello',\n",
              "  'Greetings',\n",
              "  'Hello. I am Dexter. I will serve your leave enquiries.'],\n",
              " ['hi hello',\n",
              "  'Greetings',\n",
              "  'Hello. I am Dexter. I will serve your leave enquiries.'],\n",
              " ['hi ',\n",
              "  'Greetings',\n",
              "  'Hello. I am Dexter. I will serve your leave enquiries.'],\n",
              " ['hi', 'Greetings', 'Hello. I am Dexter. I will serve your leave enquiries.'],\n",
              " ['hi', 'Greetings', 'Hello. I am Dexter. I will serve your leave enquiries.'],\n",
              " ['hey',\n",
              "  'Greetings',\n",
              "  'Hello. I am Dexter. I will serve your leave enquiries.'],\n",
              " ['hello, hi',\n",
              "  'Greetings',\n",
              "  'Hello. I am Dexter. I will serve your leave enquiries.'],\n",
              " ['hey',\n",
              "  'Greetings',\n",
              "  'Hello. I am Dexter. I will serve your leave enquiries.'],\n",
              " ['hey, hi',\n",
              "  'Greetings',\n",
              "  'Hello. I am Dexter. I will serve your leave enquiries.'],\n",
              " ['hey, hello',\n",
              "  'Greetings',\n",
              "  'Hello. I am Dexter. I will serve your leave enquiries.'],\n",
              " ['Good morning',\n",
              "  'Morning',\n",
              "  'Good Morning. I am Dexter. I will serve your leave enquiries.'],\n",
              " ['Good afternoon',\n",
              "  'Afternoon',\n",
              "  'Good afternoon. I am Dexter. I will serve your leave enquiries.'],\n",
              " ['Good evening',\n",
              "  'Evening',\n",
              "  'Good evening. I am Dexter. I will serve your leave enquiries.'],\n",
              " ['Good night', 'Goodbye', 'Good night. Take care.'],\n",
              " ['How are you today?', 'Opening', \"I'm fine! Thank you. How can I help you?\"],\n",
              " ['want help', 'Help', 'How can I help you?'],\n",
              " ['need help', 'Help', 'How can I help you?'],\n",
              " ['help me', 'Help', 'How can I help you?'],\n",
              " [\"I don't want your help.\",\n",
              "  'No-Help',\n",
              "  'Ok sir/madam. No problem. Have a nice day.'],\n",
              " [\"I don't want your assistance\",\n",
              "  'No-Help',\n",
              "  'Ok sir/madam. No problem. Have a nice day.'],\n",
              " ['No help required', 'No-Help', 'Ok sir/madam. No problem. Have a nice day.'],\n",
              " ['It has been great talking to you.',\n",
              "  'Closing',\n",
              "  \"It's glad to know that I have been helpful. Have a good day!\"],\n",
              " ['great',\n",
              "  'Closing',\n",
              "  \"It's glad to know that I have been helpful. Have a good day!\"],\n",
              " ['thank you for your help',\n",
              "  'Closing',\n",
              "  \"It's glad to know that I have been helpful. Have a good day!\"],\n",
              " ['thank you',\n",
              "  'Closing',\n",
              "  \"It's glad to know that I have been helpful. Have a good day!\"],\n",
              " ['thank you very much',\n",
              "  'Closing',\n",
              "  \"It's glad to know that I have been helpful. Have a good day!\"],\n",
              " ['thanks.',\n",
              "  'Closing',\n",
              "  \"You're welcome!It's glad to know that I have been helpful. Have a good day!\"],\n",
              " ['thanks very much',\n",
              "  'Closing',\n",
              "  \"It's glad to know that I have been helpful. Have a good day!\"],\n",
              " ['How many types of leaves are there?',\n",
              "  'Leaves-Type',\n",
              "  'Currently I know about two: annual and optional leaves.'],\n",
              " ['types of leaves?',\n",
              "  'Leaves-Type',\n",
              "  'Currently I know about two: annual and optional leaves.'],\n",
              " ['type leaves?',\n",
              "  'Leaves-Type',\n",
              "  'Currently I know about two: annual and optional leaves.'],\n",
              " ['leave type?',\n",
              "  'Leaves-Type',\n",
              "  'Currently I know about two: annual and optional leaves.'],\n",
              " ['leaves type?',\n",
              "  'Leaves-Type',\n",
              "  'Currently I know about two: annual and optional leaves.'],\n",
              " ['How many leaves have I taken?',\n",
              "  'Default-Utilized-Annual-Leaves',\n",
              "  'You have used 12 annual leaves.'],\n",
              " ['How many leaves I have already taken?',\n",
              "  'Default-Utilized-Annual-Leaves',\n",
              "  'You have used 12 annual leaves.'],\n",
              " ['how many annual leaves I took?',\n",
              "  'Utilized-Annual-Leaves',\n",
              "  'You have taken 12 annual leaves.'],\n",
              " ['How many annual leaves have I taken?',\n",
              "  'Utilized-Annual-Leaves',\n",
              "  'You have taken 12 annual leaves.'],\n",
              " ['How many annual leaves I have already taken?',\n",
              "  'Utilized-Annual-Leaves',\n",
              "  'You have taken 12 annual leaves.'],\n",
              " ['Tell me the annual leaves count I have taken?',\n",
              "  'Utilized-Annual-Leaves',\n",
              "  'You have taken 12 annual leaves.'],\n",
              " ['How many annual leaves have I taken?',\n",
              "  'Utilized-Annual-Leaves',\n",
              "  'You have taken 12 annual leaves.'],\n",
              " ['number of annual leaves taken?',\n",
              "  'Utilized-Annual-Leaves',\n",
              "  'You have taken 12 annual leaves.'],\n",
              " ['annual leaves taken?',\n",
              "  'Utilized-Annual-Leaves',\n",
              "  'You have taken 12 annual leaves.'],\n",
              " ['number of annual leaves already taken?',\n",
              "  'Utilized-Annual-Leaves',\n",
              "  'You have taken 12 annual leaves.'],\n",
              " ['annual leaves taken?',\n",
              "  'Utilized-Annual-Leaves',\n",
              "  'You have taken 12 annual leaves.'],\n",
              " ['annual leaves already taken?',\n",
              "  'Utilized-Annual-Leaves',\n",
              "  'You have taken 12 annual leaves.'],\n",
              " ['Tell me number of annual leaves I have taken',\n",
              "  'Utilized-Annual-Leaves',\n",
              "  'You have taken 12 annual leaves.'],\n",
              " ['number of annual leaves used?',\n",
              "  'Utilized-Annual-Leaves',\n",
              "  'You have taken 12 annual leaves.'],\n",
              " ['my taken annual leaves',\n",
              "  'Utilized-Annual-Leaves',\n",
              "  'You have taken 12 annual leaves.'],\n",
              " ['annual leaves used?',\n",
              "  'Utilized-Annual-Leaves',\n",
              "  'You have taken 12 annual leaves.'],\n",
              " ['How many optional leaves have I taken',\n",
              "  'Utilized-Optional-Leaves',\n",
              "  'You have taken 1 optional leaves.'],\n",
              " ['How many optional leaves I took',\n",
              "  'Utilized-Optional-Leaves',\n",
              "  'You have taken 1 optional leaves.'],\n",
              " ['optional leaves taken',\n",
              "  'Utilized-Optional-Leaves',\n",
              "  'You have taken 1 optional leaves.'],\n",
              " ['number of optional leaves I have taken?',\n",
              "  'Utilized-Optional-Leaves',\n",
              "  'You have taken 1 optional leaves.'],\n",
              " ['tell me the optional leaves count I have taken',\n",
              "  'Utilized-Optional-Leaves',\n",
              "  'You have taken 1 optional leaves.'],\n",
              " ['tell me number of optional leaves I have taken',\n",
              "  'Utilized-Optional-Leaves',\n",
              "  'You have taken 1 optional leaves.'],\n",
              " ['can you tell me number of optional leaves I have taken',\n",
              "  'Utilized-Optional-Leaves',\n",
              "  'You have taken 1 optional leaves.'],\n",
              " ['please tell me number of optional leaves I have taken',\n",
              "  'Utilized-Optional-Leaves',\n",
              "  'You have taken 1 optional leaves.'],\n",
              " ['How many optional leaves have I taken?',\n",
              "  'Utilized-Optional-Leaves',\n",
              "  'You have taken 1 optional leaves.'],\n",
              " ['number of optional leaves taken?',\n",
              "  'Utilized-Optional-Leaves',\n",
              "  'You have taken 1 optional leaves.'],\n",
              " ['number of optional leaves already taken?',\n",
              "  'Utilized-Optional-Leaves',\n",
              "  'You have taken 1 optional leaves.'],\n",
              " ['optional leaves taken?',\n",
              "  'Utilized-Optional-Leaves',\n",
              "  'You have taken 1 optional leaves.'],\n",
              " ['optional leaves already taken?',\n",
              "  'Utilized-Optional-Leaves',\n",
              "  'You have taken 1 optional leaves.'],\n",
              " ['please tell me number of optional leaves I have used.',\n",
              "  'Utilized-Optional-Leaves',\n",
              "  'You have taken 1 optional leaves.'],\n",
              " ['please tell me number of optional leaves I have used',\n",
              "  'Utilized-Optional-Leaves',\n",
              "  'You have taken 1 optional leaves.'],\n",
              " ['tell me the optional leaves count I have used.',\n",
              "  'Utilized-Optional-Leaves',\n",
              "  'You have taken 1 optional leaves.'],\n",
              " ['tell me the optional leaves count I have used',\n",
              "  'Utilized-Optional-Leaves',\n",
              "  'You have taken 1 optional leaves.'],\n",
              " ['the optional leaves count I have used',\n",
              "  'Utilized-Optional-Leaves',\n",
              "  'You have taken 1 optional leaves.'],\n",
              " ['the optional leaves count I have used?',\n",
              "  'Utilized-Optional-Leaves',\n",
              "  'You have taken 1 optional leaves.'],\n",
              " ['tell me the optional leaves count I have taken',\n",
              "  'Utilized-Optional-Leaves',\n",
              "  'You have taken 1 optional leaves.'],\n",
              " ['tell me the optional leaves count I have taken',\n",
              "  'Utilized-Optional-Leaves',\n",
              "  'You have taken 1 optional leaves.'],\n",
              " ['tell me the optional leaves count I have taken',\n",
              "  'Utilized-Optional-Leaves',\n",
              "  'You have taken 1 optional leaves.'],\n",
              " ['How many optional leaves have I used',\n",
              "  'Utilized-Optional-Leaves',\n",
              "  'You have taken 1 optional leaves.'],\n",
              " ['How many optional leaves have I used?',\n",
              "  'Utilized-Optional-Leaves',\n",
              "  'You have taken 1 optional leaves.'],\n",
              " ['number of optional leaves used?',\n",
              "  'Utilized-Optional-Leaves',\n",
              "  'You have taken 1 optional leaves.'],\n",
              " ['optional leaves used?',\n",
              "  'Utilized-Optional-Leaves',\n",
              "  'You have taken 1 optional leaves.'],\n",
              " ['How many leaves do I have?',\n",
              "  'Default-Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves left.'],\n",
              " ['How many leaves can I take?',\n",
              "  'Default-Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves left.'],\n",
              " ['How many leaves are remaining?',\n",
              "  'Default-Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves left.'],\n",
              " ['remaining leaves.',\n",
              "  'Default-Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves left.'],\n",
              " ['What are my leaves?',\n",
              "  'Default-Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves left.'],\n",
              " ['Tell me my leave balance.',\n",
              "  'Default-Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves left.'],\n",
              " ['my remaining leaves.',\n",
              "  'Default-Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves left.'],\n",
              " ['leave balance.',\n",
              "  'Default-Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves left.'],\n",
              " ['leaves pending.',\n",
              "  'Default-Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves left.'],\n",
              " ['tell me the annual leaves count I have remaining',\n",
              "  'Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves remaining.'],\n",
              " ['How many annual leaves do I have?',\n",
              "  'Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves remaining.'],\n",
              " ['What are my annual leaves?',\n",
              "  'Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves remaining.'],\n",
              " ['What is my annual leave balance?',\n",
              "  'Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves remaining.'],\n",
              " ['Tell me my annual leaves.',\n",
              "  'Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves remaining.'],\n",
              " ['How many annual leaves are remaining?',\n",
              "  'Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves remaining.'],\n",
              " ['Tell me my annual leaves remaining',\n",
              "  'Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves remaining.'],\n",
              " ['remaining annual leaves.',\n",
              "  'Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves remaining.'],\n",
              " ['annual leaves remaining.',\n",
              "  'Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves remaining.'],\n",
              " ['number of annual leaves remaining.',\n",
              "  'Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves remaining.'],\n",
              " ['number of annual leaves I have?',\n",
              "  'Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves remaining.'],\n",
              " ['annual leaves remaining.',\n",
              "  'Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves remaining.'],\n",
              " ['Please tell me the annual leaves count I have remaining.',\n",
              "  'Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves remaining.'],\n",
              " ['Tell me the annual leaves count I have remaining.',\n",
              "  'Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves remaining.'],\n",
              " ['the annual leaves count I have remaining.',\n",
              "  'Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves remaining.'],\n",
              " ['my annual leaves count remaining.',\n",
              "  'Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves remaining.'],\n",
              " ['Tell me my annual leave balance.',\n",
              "  'Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves remaining.'],\n",
              " ['annual leave balance.',\n",
              "  'Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves remaining.'],\n",
              " ['annual leaves.',\n",
              "  'Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves remaining.'],\n",
              " ['can you tell me number of annual leaves I have remaining',\n",
              "  'Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves remaining.'],\n",
              " ['please tell me number of annual leaves I have remaining',\n",
              "  'Balance-Annual-Leaves',\n",
              "  'You have 25 annual leaves remaining.'],\n",
              " ['How many optional leaves are remaining?',\n",
              "  'Balance-Optional-Leaves',\n",
              "  'You have 2 optional leaves remaining.'],\n",
              " ['optional leaves remaining?',\n",
              "  'Balance-Optional-Leaves',\n",
              "  'You have 2 optional leaves remaining.'],\n",
              " ['number of optional leaves I have remaining?',\n",
              "  'Balance-Optional-Leaves',\n",
              "  'You have 2 optional leaves remaining.'],\n",
              " ['How many optional leaves do I have?',\n",
              "  'Balance-Optional-Leaves',\n",
              "  'You have 2 optional leaves remaining.'],\n",
              " ['How many optional leaves do I have',\n",
              "  'Balance-Optional-Leaves',\n",
              "  'You have 2 optional leaves remaining.'],\n",
              " ['Tell me my optional leave balance?',\n",
              "  'Balance-Optional-Leaves',\n",
              "  'You have 2 optional leaves remaining.'],\n",
              " ['Tell me my optional leaves left?',\n",
              "  'Balance-Optional-Leaves',\n",
              "  'You have 2 optional leaves remaining.'],\n",
              " ['How many optional leaves can I take?',\n",
              "  'Balance-Optional-Leaves',\n",
              "  'You have 2 optional leaves remaining.'],\n",
              " ['optional leaves take?',\n",
              "  'Balance-Optional-Leaves',\n",
              "  'You have 2 optional leaves remaining.'],\n",
              " ['How many optional leaves I have?',\n",
              "  'Balance-Optional-Leaves',\n",
              "  'You have 2 optional leaves remaining.'],\n",
              " ['Tell me my optional leave balance.',\n",
              "  'Balance-Optional-Leaves',\n",
              "  'You have 2 optional leaves remaining.'],\n",
              " ['tell me the optional leaves count I have remaining',\n",
              "  'Balance-Optional-Leaves',\n",
              "  'You have 2 optional leaves remaining.'],\n",
              " ['optional leaves.',\n",
              "  'Balance-Optional-Leaves',\n",
              "  'You have 2 optional leaves remaining.'],\n",
              " ['optional leaves?',\n",
              "  'Balance-Optional-Leaves',\n",
              "  'You have 2 optional leaves remaining.'],\n",
              " ['optional leave balance',\n",
              "  'Balance-Optional-Leaves',\n",
              "  'You have 2 optional leaves remaining.'],\n",
              " ['optional',\n",
              "  'Balance-Optional-Leaves',\n",
              "  'You have 2 optional leaves remaining.'],\n",
              " ['Tell me the optional leaves count I have remaining.',\n",
              "  'Balance-Optional-Leaves',\n",
              "  'You have 2 optional leaves remaining.'],\n",
              " ['the optional leaves count I have remaining?',\n",
              "  'Balance-Optional-Leaves',\n",
              "  'You have 2 optional leaves remaining.'],\n",
              " ['my optional leaves count remaining.',\n",
              "  'Balance-Optional-Leaves',\n",
              "  'You have 2 optional leaves remaining.'],\n",
              " ['please tell me number of optional leaves I have remaining',\n",
              "  'Balance-Optional-Leaves',\n",
              "  'You have 2 optional leaves remaining.'],\n",
              " ['please tell me number of optional leaves I have remaining.',\n",
              "  'Balance-Optional-Leaves',\n",
              "  'You have 2 optional leaves remaining.'],\n",
              " ['number of optional leaves I have remaining.',\n",
              "  'Balance-Optional-Leaves',\n",
              "  'You have 2 optional leaves remaining.'],\n",
              " ['number of optional leaves I have',\n",
              "  'Balance-Optional-Leaves',\n",
              "  'You have 2 optional leaves remaining.'],\n",
              " ['number of optional leaves?',\n",
              "  'Balance-Optional-Leaves',\n",
              "  'You have 2 optional leaves remaining.'],\n",
              " ['How many carry forward leaves do I have?',\n",
              "  'CF',\n",
              "  'You have 30 carry forward leaves.'],\n",
              " ['number of carry forward leaves I have?',\n",
              "  'CF',\n",
              "  'You have 30 carry forward leaves.'],\n",
              " ['tell me the carry forward leaves count I have',\n",
              "  'CF',\n",
              "  'You have 30 carry forward leaves.'],\n",
              " ['tell me number of carry forward leaves I have',\n",
              "  'CF',\n",
              "  'You have 30 carry forward leaves.'],\n",
              " ['can you tell me number of carry forward leaves I have',\n",
              "  'CF',\n",
              "  'You have 30 carry forward leaves.'],\n",
              " ['please tell me number of carry forward leaves I have',\n",
              "  'CF',\n",
              "  'You have 30 carry forward leaves.'],\n",
              " ['How many carry forwards do I have from previous year?',\n",
              "  'CF',\n",
              "  'You have 30 carry forward leaves.'],\n",
              " ['Tell me my carry forward leaves from previous year',\n",
              "  'CF',\n",
              "  'You have 30 carry forward leaves.'],\n",
              " ['Tell me my carry forward leaves',\n",
              "  'CF',\n",
              "  'You have 30 carry forward leaves.'],\n",
              " ['Tell me carry forward leaves', 'CF', 'You have 30 carry forward leaves.'],\n",
              " ['carry forward leaves', 'CF', 'You have 30 carry forward leaves.'],\n",
              " ['carry forward leave', 'CF', 'You have 30 carry forward leaves.'],\n",
              " ['carry forward', 'CF', 'You have 30 carry forward leaves.'],\n",
              " ['previous year carry forward leaves',\n",
              "  'CF',\n",
              "  'You have 30 carry forward leaves.']]"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D075kFt5V4a2"
      },
      "source": [
        "features_data, corpus, answers = extract_feature_from_doc(data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lN5ynsnRWDdS"
      },
      "source": [
        "print(features_data[50])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bUbVBd7aWK74"
      },
      "source": [
        "corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FwYhlxwsWQHV"
      },
      "source": [
        "answers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XbsZ6e4aWjLC"
      },
      "source": [
        "**TRAIN A MODEL USING THESE FEATURES**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qlgf90siZBNJ"
      },
      "source": [
        "split_ratio = 0.8\n",
        "# 80% training and 20% test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLI4IZaCZP_j"
      },
      "source": [
        "def split_dataset(data,split_ratio):\n",
        "  random.shuffle(data)                   #shuff ling the data internally\n",
        "  data_length = len(data)                # size of dataset\n",
        "  train_split = int(data_length * split_ratio) # size of training data\n",
        "  return (data[:train_split]) , (data[train_split:]) #returning both the training data and test data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCJfgvJXapJX"
      },
      "source": [
        "training_data, test_data = split_dataset(features_data, split_ratio)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7IKz24TAbwEu"
      },
      "source": [
        "**CLASSIFICATION USING DECISION TREE **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKjoHExjb9AL"
      },
      "source": [
        "#Things to know about decision tree classifier :\n",
        "# Training a decision tree classifier is done by creating a structure where each node corresponds to a feature name\n",
        "# and branches corresponds to feature value and tracing down the branches you get to the leaves of the tree which are the classification labels\n",
        "## entropy cutoff used during tree refinement process, \n",
        "  # one is where the default values can be taken and tree is created but the the tree creation needs to be refined to get to the optimal values way of reaching\n",
        "  # to the leaves. So the tree refinement process is how the tree decides to create branches. if the entropy of the probability distribution of a label\n",
        "  # choices in the tree is greater than the entropy value then the tree is more refined by creating more branches, but if it lower then it is hold. Then\n",
        "  # the other hyperparameter is support_cutoff controls how many leabeled features are required to refine the trees for e.g. if we need to classify greetings\n",
        "  # as one of the category then, how many of those features I need for that refinement process. Decision tree classifier class refines itself. Labeled\n",
        "  # features sets are eliminated. they no longer provide values to the training set. When the number of labeled features are less than or equal to the support\n",
        "  # cutoff, then the refinement stops for atleast that section of the tree. So if the support cutoff  speicifies minimum number of instances that\n",
        "  # are required to make a decision about a feature. for e.g., if there is a decision needs to be made about a particular feature which in this case could be\n",
        "  # carri, so there must be 6 instances in the input features that has carri as an example. so if there are less than th\n",
        "  #e 6 instances then the refinement should come to a stop\n",
        "def train_using_decision_tree(training_data, test_data):\n",
        "  classifier = nltk.classify.DecisionTreeClassifier.train(training_data, entropy_cutoff=0.6, support_cutoff=6) \n",
        "  classifier_name = type(classifier).__name__\n",
        "  training_set_accuracy = nltk.classify.accuracy(classifier, training_data)\n",
        "  print('training set accuracy:', training_set_accuracy)\n",
        "  test_set_accuracy = nltk.classify.accuracy(classifier, test_data)\n",
        "  print('test set accuracy:', test_set_accuracy)\n",
        "  return classifier, classifier_name, test_set_accuracy, training_set_accuracy\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N_CCEB7Qjas2",
        "outputId": "109a768d-cdb3-4ac6-8079-becdda18fe3f"
      },
      "source": [
        "dtclassifer, classifier_name, test_set_accuracy, training_set_accuracy = train_using_decision_tree(training_data, test_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training set accuracy: 0.6491228070175439\n",
            "test set accuracy: 0.3793103448275862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PecG8bhmLRV"
      },
      "source": [
        "**NAIVE BAYES CLASSIFICATION**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lSWF2relkcU4"
      },
      "source": [
        "def train_using_naive_bayes(training_data, test_data):\n",
        "  classifier = nltk.classify.NaiveBayesClassifier.train(training_data) \n",
        "  classifier_name = type(classifier).__name__\n",
        "  training_set_accuracy = nltk.classify.accuracy(classifier, training_data)\n",
        "  test_set_accuracy = nltk.classify.accuracy(classifier, test_data)\n",
        "  return classifier, classifier_name, test_set_accuracy, training_set_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aZOYRVGNlEgU",
        "outputId": "2a3d77d3-e957-401c-b5de-5ee9a9e254f9"
      },
      "source": [
        "classifer, classifier_name, test_set_accuracy, training_set_accuracy = train_using_naive_bayes(training_data, test_data)\n",
        "print('training set accuracy:', training_set_accuracy)\n",
        "print('test set accuracy:', test_set_accuracy)\n",
        "print(len(classifer.most_informative_features()))\n",
        "classifer.show_most_informative_features()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training set accuracy: 0.6578947368421053\n",
            "test set accuracy: 0.4482758620689655\n",
            "54\n",
            "Most Informative Features\n",
            "                    leav = None           Greeti : Balanc =     14.0 : 1.0\n",
            "                    help = True             Help : Closin =      4.1 : 1.0\n",
            "                 alreadi = True           Defaul : Utiliz =      4.0 : 1.0\n",
            "                 forward = None           Balanc : CF     =      3.6 : 1.0\n",
            "                  remain = True           Balanc : Defaul =      2.9 : 1.0\n",
            "                   count = True           Utiliz : Balanc =      2.9 : 1.0\n",
            "                   carri = None           Balanc : CF     =      2.8 : 1.0\n",
            "                   taken = None           Balanc : Utiliz =      2.7 : 1.0\n",
            "                   thank = None           Balanc : Closin =      2.7 : 1.0\n",
            "                    help = None           Balanc : No-Hel =      2.6 : 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "vpSIiF3um-LO",
        "outputId": "dfadcbea-ab91-457c-af62-b03ba6103a62"
      },
      "source": [
        "classifer.classify(({'mani':True, 'option':True, 'leav':True}))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Balance-Optional-Leaves'"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ug6JwexzUoFW",
        "outputId": "336cb5dd-4847-4f6b-8364-45142838c3c6"
      },
      "source": [
        "extract_feature(\"hello\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['hello']"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fatZUn-9UwQp",
        "outputId": "695eea21-8287-48cf-9c47-9afd1ee22062"
      },
      "source": [
        "word_feats(extract_feature(\"hello\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'hello': True}"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "yOJuhANTVOEm",
        "outputId": "1506adcb-b0b1-4bb7-98e9-100cd1819b07"
      },
      "source": [
        "input_sentence = \"how many balanced leaves do I have\"\n",
        "classifer.classify(word_feats(extract_feature(input_sentence)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Balance-Optional-Leaves'"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qszOVr6VoKB"
      },
      "source": [
        "def reply(input_sentence):\n",
        "  category = dtclassifer.classify(word_feats(extract_feature(input_sentence)))\n",
        "  return answers[category]\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "V0aPBycoV601",
        "outputId": "ea860301-1c93-47a5-8cf8-4d3d967dc35e"
      },
      "source": [
        "reply('Hi')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Hello. I am Dexter. I will serve your leave enquiries.'"
            ]
          },
          "metadata": {},
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "ZWVWewSQV-IB",
        "outputId": "47879b7a-556c-4cbc-dbb4-dc1a0baedf25"
      },
      "source": [
        "reply('How many annual leaves do I have left?')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'You have 2 optional leaves remaining.'"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "aYgcBDfGWFNo",
        "outputId": "605a1412-ac6a-4f51-f151-1d73d9a4ac2d"
      },
      "source": [
        "reply('How many leaves have I taken?')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'You have taken 1 optional leaves.'"
            ]
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "OAAKsyCXWL56",
        "outputId": "b82ff228-6afd-4844-e897-167b71ea981f"
      },
      "source": [
        "reply('Thanks!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"It's glad to know that I have been helpful. Have a good day!\""
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-4e6o7skF5C"
      },
      "source": [
        ""
      ]
    }
  ]
}